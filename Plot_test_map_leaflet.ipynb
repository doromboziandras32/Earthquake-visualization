{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some test to exxtract stanford dataset\n",
    "#!pip install dash-leaflet\n",
    "#!pip install obspy\n",
    "#!pip install dash-extensions\n",
    "#!pip install librosa\n",
    "#!pip install dash-bootstrap-components\n",
    "#!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics layer: heatmap by geographic regions, heatmap by countries\n",
    "# Global regions: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CQWUBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dash-extensions==0.0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import obspy\n",
    "#import h5py\n",
    "from obspy import UTCDateTime\n",
    "import numpy as np\n",
    "from obspy.clients.fdsn.client import Client\n",
    "import matplotlib.pyplot as pl\n",
    "from obspy.clients.fdsn.header import URL_MAPPINGS\n",
    "\n",
    "#df_test = pd.read_csv(\"csvs/chunk5.csv\")\n",
    "df_test = pd.read_csv(\"csvs/earthquake_metadata.csv\",low_memory=False)\n",
    "\n",
    "df_test.set_index('trace_name',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_list = sorted(URL_MAPPINGS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(df_test['source_distance_km'])\n",
    "\n",
    "df_test_closest = df_test[df_test['source_distance_km'] == min(df_test['source_distance_km'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude normalization init test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "#Extract the proper seismic instrument\n",
    "#index: 0: north-south, 1: east-west, 2:vertical\n",
    "def create_seismic_sound_to_dash_bytes(x):\n",
    "    #print('Read')\n",
    "    x1 = x.data\n",
    "    #print('Normalize')\n",
    "    norm_x =  x1/x1.std()\n",
    "    #print('Resample')\n",
    "    #norm_x_resampled = norm_x.resample(8000)\n",
    "    #Pass orig_sr=50.0, target_sr=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
    "    norm_x_resampled = librosa.resample(norm_x, orig_sr = x.stats.sampling_rate, target_sr=8000)\n",
    "    #print('Export')\n",
    "    out_audio = BytesIO()\n",
    "    #norm_x_resampled = librosa.resample(norm_x, 100, 8000)\n",
    "    sf.write(out_audio,norm_x_resampled,8000,format = 'wav')\n",
    "\n",
    "    #import base64 \n",
    "    #encoded=base64.b64encode(open(\"file.wav\").read())\n",
    "    \n",
    "\n",
    "    #encoded=base64.b64encode(norm_x_resampled).decode(\"ascii\").replace(\"\\n\", \"\")\n",
    "    out_audio.seek(0)\n",
    "    encoded=base64.b64encode(out_audio.read()).decode(\"ascii\").replace(\"\\n\", \"\")\n",
    "    \n",
    "    #encoded.see\n",
    "    \n",
    "\n",
    "    #print(encoded)\n",
    "\n",
    "    return \"data:audio/wav;base64,{}\".format(encoded)\n",
    "\n",
    "    #return out_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Build up velocity\n",
    "https://docs.obspy.org/contents.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression, amplitude normalization:\n",
    "https://librosa.org/doc/main/generated/librosa.effects.time_stretch.html\n",
    "https://superkogito.github.io/blog/rmsnormalization.html\n",
    "\n",
    "https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.remove_response.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.obspy.org/tutorial/code_snippets/filtering_seismograms.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64\n",
    "def fig_to_uri(in_fig, close_all=True, **save_args):\n",
    "    # type: (plt.Figure) -> str\n",
    "    \"\"\"\n",
    "    Save a figure as a URI\n",
    "    :param in_fig:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    px = 1/plt.rcParams['figure.dpi']\n",
    "    fig = plt.figure(figsize=(600*px, 200*px))\n",
    "    \n",
    "    out_img = BytesIO()\n",
    "    if isinstance(in_fig,obspy.core.Trace):\n",
    "        #in_fig.plot(outfile =out_img, format='png', size = (600,200) )\n",
    "        in_fig.plot(fig = fig )\n",
    "        fig.savefig(out_img, format='png', **save_args)\n",
    "        if close_all:\n",
    "            fig.clf()            \n",
    "            plt.close('all')   \n",
    "    else:    \n",
    "        in_fig.savefig(out_img, format='png', **save_args)\n",
    "        if close_all:\n",
    "            in_fig.clf()\n",
    "            plt.close('all')        \n",
    "    \n",
    "    out_img.seek(0)  # rewind file\n",
    "    encoded = base64.b64encode(out_img.read()).decode(\"ascii\").replace(\"\\n\", \"\")\n",
    "    #return encoded\n",
    "    return \"data:image/png;base64,{}\".format(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import base64\n",
    "from scipy import signal\n",
    "def spectrogram_to_uri(input_data, close_all=True, **save_args):    \n",
    "    #todo: maybe we might be able to make a bytewriter approach, which is easier, and can be used for seismic plot and spectrograms at once\n",
    "    \n",
    "    #f, t, Sxx = signal.spectrogram(input_data.filter(\"highpass\", freq=0.5).data, input_data.stats.sampling_rate)\n",
    "    px = 1/plt.rcParams['figure.dpi']\n",
    "    plt.figure(figsize=(600*px, 200*px))\n",
    "    f, t, Sxx,e = plt.specgram(x = input_data.filter(\"highpass\", freq=0.5).data, Fs = input_data.stats.sampling_rate,scale = 'dB',cmap = 'viridis')\n",
    "    \n",
    "    #plt.pcolormesh(t, f, np.log10(Sxx))\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    #plt.show()\n",
    "\n",
    "    # type: (plt.Figure) -> str\n",
    "    \"\"\"\n",
    "    Save a figure as a URI\n",
    "    :param in_fig:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    out_img = BytesIO()\n",
    "    plt.savefig(out_img, format='png', **save_args)\n",
    "    if close_all:\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "    out_img.seek(0)  # rewind file\n",
    "    encoded = base64.b64encode(out_img.read()).decode(\"ascii\").replace(\"\\n\", \"\")\n",
    "    #return encoded\n",
    "    return \"data:image/png;base64,{}\".format(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from io import BytesIO\n",
    "import base64\n",
    "def spectrogram_to_uri(in_fig, close_all=True, **save_args):\n",
    "    # type: (plt.Figure) -> str\n",
    "    \"\"\"\n",
    "    Save a figure as a URI\n",
    "    :param in_fig:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    out_img = BytesIO()\n",
    "    if isinstance(in_fig,obspy.core.Trace):\n",
    "        #print('Trace')\n",
    "        in_fig.spectrogram(outfile =out_img,fmt  = 'png',show =False)\n",
    "        \n",
    "    else:    \n",
    "        in_fig.savefig(out_img, format='png', **save_args)\n",
    "        if close_all:\n",
    "            in_fig.clf()\n",
    "            plt.close('all')        \n",
    "    \n",
    "    out_img.seek(0)  # rewind file\n",
    "    encoded = base64.b64encode(out_img.read()).decode(\"ascii\").replace(\"\\n\", \"\")\n",
    "    #return encoded\n",
    "    return \"data:image/png;base64,{}\".format(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test['time'] = pd.to_datetime(df_test['trace_start_time'], infer_datetime_format=True)\n",
    "df_test['source_depth_km'] = pd.to_numeric(df_test['source_depth_km'],errors='coerce')\n",
    "df_test['source_magnitude'] = pd.to_numeric(df_test['source_magnitude'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_waveform(client, event_record):\n",
    "    wave = client.get_waveforms(network=event_record['network_code'],\n",
    "                            station=event_record['receiver_code'],\n",
    "                            starttime=UTCDateTime(event_record['time']),\n",
    "                                endtime=UTCDateTime(event_record['time']) + 60,\n",
    "                                location = \"*\",\n",
    "                                channel = \"*\")\n",
    "    \n",
    "    #temprorarily extract only one stream\n",
    "    return wave[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations_df = pd.read_csv('stations_duplicates_removed.csv')\n",
    "stations_df = pd.read_csv('csvs/stations_definition.csv')\n",
    "stations_df['station_opened'] =  pd.to_datetime(stations_df['station_opened'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_test\n",
    "#stations_df = stations_df\n",
    "#stations_df[\n",
    "stations_df = stations_df[stations_df['station_id'].isin(stations)]\n",
    "stations_df.to_csv('csvs/stations_definition.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_event = df_test.loc['KAN08.GS_20150408005359_EV']\n",
    "\n",
    "provider_of_waveform = stations_df[(stations_df['network_name'] == selected_event['network_code']) &  (stations_df['station_name'] == selected_event['receiver_code'])]\n",
    "clien = provider_of_waveform['provider'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clien = Client(clien)\n",
    "wave_test = extract_waveform(clien, selected_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_file = create_seismic_sound_to_dash_bytes(wave_test)\n",
    "spectrogram_plot = spectrogram_to_uri(wave_test)\n",
    "\n",
    "base_seismogram = fig_to_uri(wave_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_colnames = ['trace_name','location','latitude','longitude','event_recorded_at','earthquake_depth','earthquake_magnitude']\n",
    "#info_colnames = ['trace_name','latitude','longitude','event_recorded_at','earthquake_depth','earthquake_magnitude']\n",
    "def create_event_infos(x):\n",
    "    #'time','source_depth_km','source_magnitude','trace_name','source_latitude','source_longitude','trace_category'\n",
    "    #selected_record = df_test.loc[x['trace_name']]\n",
    "    selected_record = df_test.loc[x]\n",
    "    latitude = str(selected_record['source_latitude'])\n",
    "    longitude = str(selected_record['source_longitude'])\n",
    "    address_details = ['road','county','state', 'country']\n",
    "    try:\n",
    "        location = geolocator.reverse(latitude + \",\" + longitude, language='en').raw\n",
    "        location_string = str()\n",
    "        for a in address_details:\n",
    "            try:\n",
    "                location_string += location['address'][a]\n",
    "                location_string += ', '\n",
    "\n",
    "            except KeyError:\n",
    "                pass\n",
    "        \n",
    "        location_string = location_string[:-2]\n",
    "    except AttributeError:\n",
    "        location_string = \"N/A\"\n",
    "\n",
    "\n",
    "    #print(location)\n",
    "    info_dict = dict()\n",
    "    info_dict['trace_name'] = x\n",
    "    info_dict['location'] = location_string\n",
    "    info_dict['latitude'] = latitude\n",
    "    info_dict['longitude'] = longitude\n",
    "    info_dict['event_recorded_at'] = str(selected_record['time'])\n",
    "    info_dict['earthquake_depth'] = f'{selected_record[\"source_depth_km\"]} km'\n",
    "    info_dict['earthquake_magnitude'] = f'{selected_record[\"source_magnitude\"]} km'\n",
    "\n",
    "    return pd.DataFrame.from_dict(info_dict, orient='index').reset_index().to_dict('records')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Extract the minimum depth, magnitude, recording times etcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Latitudes and longitudes\n",
    "site_lat = df_test.source_latitude\n",
    "site_lon = df_test.source_longitude\n",
    "hover_desc = 'Timestamp: ' +  str(df_test.time) + '<br>Category: ' + df_test.trace_category\n",
    "#hover_desc = f'Time of registration: {df_earthquake_detections.trace_start_time} <br> Category: {df_earthquake_detections.trace_category}'\n",
    "#time = df_earthquake_detections.trace_start_time\n",
    "#ctg =df_earthquake_detections.trace_category\n",
    "#locations_name = df.text\n",
    "#min timestamp\n",
    "#Extract timestamp range\n",
    "min_date = min(df_test['time']).date()\n",
    "max_date = max(df_test['time']).date()\n",
    "#Extract minimum and maximum depth\n",
    "min_depth = min(df_test['source_depth_km'])\n",
    "max_depth = max(df_test['source_depth_km'])\n",
    "#Extract minimum and maximum magnitude\n",
    "min_magnitude = min(df_test['source_magnitude'])\n",
    "max_magnitude = max(df_test['source_magnitude'])\n",
    "\n",
    "depth_space = np.linspace(start=min_depth,stop=max_depth,num=8,endpoint=True,dtype=np.float64)\n",
    "magnitude_space = np.linspace(start=min_magnitude,stop=max_magnitude,num=8,endpoint=True,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash_leaflet.express as dlx  \n",
    "def stations_df_to_geojson(x):\n",
    "    #df_points = x[['trace_name','source_latitude','source_longitude']]    \n",
    "    df_points = x.groupby(['station_id','network_name','station_name','latitude','longitude','station_opened','station_closed'], dropna=False)['provider'].apply(list).reset_index()\n",
    "    df_points_records_renamed = df_points.rename(columns = {'latitude' :'lat','longitude' :'lon'}).to_dict('records')\n",
    "    return dlx.dicts_to_geojson(df_points_records_renamed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_list = stations_df['provider'].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations_geojson = stations_df_to_geojson(stations_df.head(10))\n",
    "stations_geojson = stations_df_to_geojson(stations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dataframe_to_geojson(x):\n",
    "    df_points = x.reset_index()[['trace_name','source_latitude','source_longitude','source_magnitude']]\n",
    "    df_points_records_renamed = df_points.rename(columns = {'source_latitude' :'lat','source_longitude' :'lon'}).to_dict('records')\n",
    "    return dlx.dicts_to_geojson(df_points_records_renamed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points_geojson = dataframe_to_geojson(df_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea: Extract station and the corresponding earthquakes, construct a polygon based on the corresponding earthquakes, extract the radius of polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea: Extract station and the corresponding earthquakes, construct a polygon based on the corresponding earthquakes, extract the radius of polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andras\\anaconda3\\envs\\interdisciplinary_leaflet\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: \n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n",
      "  \n",
      "C:\\Users\\Andras\\anaconda3\\envs\\interdisciplinary_leaflet\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning:\n",
      "\n",
      "\n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "\n",
      "C:\\Users\\Andras\\anaconda3\\envs\\interdisciplinary_leaflet\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning:\n",
      "\n",
      "\n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "import dash_leaflet as dl\n",
    "import dash_leaflet.express as dlx\n",
    "from dash import Dash, html, dcc, Output, Input\n",
    "from dash_extensions.javascript import assign\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_table\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import base64\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "\n",
    "import dash_bootstrap_components as dbc\n",
    "#from dash import  dash_table\n",
    "import dash_table\n",
    "from datetime import date\n",
    "from dash.dependencies import Input,Output,State\n",
    "from dash import callback_context\n",
    "from geopy.geocoders import Nominatim\n",
    "import dash_leaflet as dl\n",
    "from dash_extensions.javascript import assign\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "colorscale = ['red', 'yellow', 'green', 'blue', 'purple']  # rainbow\n",
    "chroma = \"https://cdnjs.cloudflare.com/ajax/libs/chroma-js/2.1.0/chroma.min.js\"  # js lib used for colors\n",
    "color_prop = 'source_magnitude'\n",
    "colorbar = dl.Colorbar(colorscale=colorscale, width=20, height=150, min=min_magnitude, max=max_magnitude, unit='km')\n",
    "detail_colorbar = dl.Colorbar(colorscale=colorscale, width=20, height=150,  unit='km', min=min_magnitude, max=max_magnitude, id = 'detail_map_colorbar')\n",
    "# Geojson rendering logic, must be JavaScript as it is executed in clientside.\n",
    "point_to_layer = assign(\"\"\"function(feature, latlng, context){\n",
    "    const {min, max, colorscale, circleOptions, colorProp} = context.props.hideout;\n",
    "    const csc = chroma.scale(colorscale).domain([min, max]);  // chroma lib to construct colorscale\n",
    "    circleOptions.fillColor = csc(feature.properties[colorProp]);  // set color based on color prop.\n",
    "    return L.circleMarker(latlng, circleOptions);  // sender a simple circle marker.\n",
    "}\"\"\")\n",
    "\n",
    "\n",
    "#icons/antenna_img.png\n",
    "# \n",
    "# `https://github.com/doromboziandras32/Interdisciplinary/blob/master/icons/antenna_img.png`\n",
    "draw_antenna = assign(\"\"\"function(feature, latlng){\n",
    "const antenna = L.icon({iconUrl: `/static/antenna_img.png`, iconSize: [24,24]});\n",
    "return L.marker(latlng, {icon: antenna});\n",
    "}\"\"\")\n",
    "\n",
    "\n",
    "draw_antenna_on_detail_map = assign(\"\"\"function(feature, latlng){\n",
    "const antenna = L.icon({iconUrl: `/static/antenna_img.png`, iconSize: [40,40]});\n",
    "return L.marker(latlng, {icon: antenna});\n",
    "}\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "#https://fonts.google.com/icons?selected=Material%20Icons%3Asettings_input_antenna%3A\n",
    "\n",
    "#geojson_filter = assign(\"function(feature, context){return context.props.hideout.includes(feature.properties.trace_name);}\")\n",
    "#default_available_earthquake_forms = df_test.index.tolist()\n",
    "app = Dash(external_scripts=[chroma], prevent_initial_callbacks=True)\n",
    "\n",
    "app.layout = html.Div([dbc.Row([\n",
    "\n",
    "                                #Filters|\n",
    "                                html.Div(style={'width':'20%','marginLeft': 5, 'marginRight': 10,'display':'inline-block',\"border\":\"2px black solid\",'vertical-align': 'top'},\n",
    "                                         children = [\n",
    "                                            #html.Div([\n",
    "                                            # dcc.Graph: maybe define somehow here?\n",
    "                                            #dcc.Graph(figure=fig, id='map-layout')]),\n",
    "                                             #'width':'15%','marginLeft': 20, 'marginRight': 20,\n",
    "                                            html.Div(style={ 'display': 'block','vertical-align':'middle'},\n",
    "                                                     children = [\n",
    "                                                        html.Br(),\n",
    "                                                        html.H3('Select which providers events and stations would be shown'),\n",
    "                                                        html.Br(),\n",
    "                                                    #Datepicker to filter for intervals\n",
    "                                                         dcc.Dropdown(id='provider-selector', \n",
    "                                                            options=[{'label': i, 'value': i} for i in provider_list],\n",
    "                                                            multi=True, \n",
    "                                                            value = provider_list,\n",
    "                                                            style={},\n",
    "                                                            className='stockselector',\n",
    "                                                            clearable=False,\n",
    "                                                            placeholder = 'Select providers..',\n",
    "                                                            \n",
    "                                                            )]), \n",
    "                                            html.Div(style={ 'display': 'block','vertical-align':'middle'},\n",
    "                                                     children = [\n",
    "                                                        html.Br(),\n",
    "                                                        html.H3('Select a date interval'),\n",
    "                                                        html.Br(),\n",
    "                                                    #Datepicker to filter for intervals\n",
    "                                                        dcc.DatePickerRange(\n",
    "                                                            id='date-filter',\n",
    "                                                            #min_date_allowed=date(1993, 1, 10),\n",
    "                                                            min_date_allowed=min_date,\n",
    "                                                            max_date_allowed=max_date,\n",
    "                                                            #max_date_allowed=date(2019, 9, 19),\n",
    "                                                            initial_visible_month=min_date,\n",
    "                                                            start_date=min_date,\n",
    "                                                            end_date=max_date\n",
    "                                                        )]),\n",
    "                                            #'width':'15%','marginLeft': 20, 'marginRight': 20,'marginTop':30,\n",
    "                                            html.Div(\n",
    "                                                style={ 'display': 'block','vertical-align':'middle'},\n",
    "                                                children = [\n",
    "                                                html.Br(),\n",
    "                                                html.H3('Select earthquake depth interval ( in km)'),\n",
    "                                                html.Br(),\n",
    "                                                #slider to filter for depth\n",
    "                                                dcc.RangeSlider(min = min_depth, max = max_depth,\n",
    "                                                                id='depth-slider',\n",
    "                                                                marks={i: '{:.2f}'.format(i) for i in depth_space},\n",
    "                                                                value=[min_depth, max_depth],\n",
    "                                                                dots=False,\n",
    "                                                                #step=\n",
    "                                                                step=0.01,\n",
    "                                                                updatemode='drag',\n",
    "                                                                tooltip={\"placement\": \"bottom\", \"always_visible\": False}\n",
    "                                            )]),\n",
    "                                             #'width':'15%','marginLeft': 20, 'marginRight': 20,'marginTop':30,\n",
    "                                            html.Div(\n",
    "                                                style={'display': 'block','vertical-align':'middle'},\n",
    "                                                children = [\n",
    "                                                html.Br(),\n",
    "                                                html.H3('Select earthquake magnitude interval ( in km)'),\n",
    "                                                html.Br(),\n",
    "                                                #slider to filter for magnitudes\n",
    "                                                dcc.RangeSlider(min = min_magnitude, max = max_magnitude,\n",
    "                                                                id='magnitude-slider',\n",
    "                                                                marks={i: '{:.2f}'.format(i) for i in magnitude_space},\n",
    "                                                                value=[min_magnitude, max_magnitude],\n",
    "                                                                dots=False,\n",
    "                                                                step=0.01,\n",
    "                                                                updatemode='drag',\n",
    "                                                                tooltip={\"placement\": \"bottom\", \"always_visible\": False}\n",
    "                                                                ),\n",
    "                                                ]),\n",
    "                                             html.Div(\n",
    "                                                 style={'display': 'block','vertical-align':'middle'},\n",
    "                                                 children = [\n",
    "                                                             html.Button('Apply Filters', id='filter-apply-btn', n_clicks=0),\n",
    "                                                             html.Button('Reset Filters', id='filter-reset-btn', n_clicks=0)\n",
    "                                                             ]\n",
    "                                             )\n",
    "                                         ]),\n",
    "                                #Map\n",
    "                                html.Div(\n",
    "                                        style={'width':'75%', 'marginRight': 0.8,'display':'inline-block',\"border\":\"2px black solid\"},                                        \n",
    "                                        children = [dl.Map(children=[\n",
    "                                                    dl.TileLayer(),\n",
    "                                                    dl.GeoJSON(data = data_points_geojson,\n",
    "                                                    #options=dict(filter=geojson_filter), \n",
    "                                                    #hideout=default_available_earthquake_forms ,\n",
    "                                                    options=dict(pointToLayer=point_to_layer),  # how to draw points            \n",
    "                                                    #options=dict(pointToLayer=point_to_layer_detail_map), \n",
    "                                                    #hideout=dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=5),\n",
    "                                                    hideout=dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=10),\n",
    "                                                    min=min_magnitude, max=max_magnitude, colorscale=colorscale),                                                    \n",
    "                                                    cluster=True , zoomToBoundsOnClick=True,\n",
    "                                                    superClusterOptions={\"radius\": 100},\n",
    "                                                    \n",
    "                                                    id ='earthquake_events_geojson'),\n",
    "                                                    dl.GeoJSON(data=stations_geojson\n",
    "                                                                , options=dict(pointToLayer=draw_antenna), zoomToBounds=True,\n",
    "                                                                clusterToLayer=draw_antenna,\n",
    "                                                                cluster=True ,  # how to draw clusters\n",
    "                                                                zoomToBoundsOnClick=True,\n",
    "                                                                superClusterOptions=dict(radius=150),\n",
    "                                                                id= 'stations_geojson')  # when true, zooms to bounds of feature (e.g. cluster) on click)\n",
    "                                                    ,colorbar                                                                \n",
    "                                                ],\n",
    "                                                 style={'width': '67%', 'height': '50vh', 'margin': \"auto\", \"display\": \"inline-block\",\"border-right\":\"5px black solid\"}, id=\"map\"),\n",
    "                                                 dl.Map(children=[\n",
    "                                                    dl.TileLayer(),\n",
    "                                                    dl.GeoJSON(\n",
    "                                                                #data = dataframe_to_geojson(df_test.head(1)),\n",
    "                                                                #options=dict(filter=geojson_filter), \n",
    "                                                                #hideout=default_available_earthquake_forms ,\n",
    "                                                                options=dict(pointToLayer=point_to_layer),  # how to draw points            \n",
    "                                                                #hideout=dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=5),\n",
    "                                                                hideout=dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=15),\n",
    "                                                                min=min_magnitude, max=max_magnitude, colorscale=colorscale), \n",
    "                                                                zoomToBoundsOnClick=True,\n",
    "                                                                zoomToBounds=True,                                              \n",
    "                                                                id ='detail_map_earthquake_geojson'),\n",
    "                                                    dl.GeoJSON( options=dict(pointToLayer=draw_antenna_on_detail_map),                                                                \n",
    "                                                                  # how to draw clusters\n",
    "                                                                zoomToBoundsOnClick=True,                                                                \n",
    "                                                                id= 'detail_map_stations_geojson'),                                                    \n",
    "                                                    detail_colorbar\n",
    "                                                 ]\n",
    "                                                 ,\n",
    "                                                 style={'width': '30%', 'height': '50vh', 'margin': \"auto\", \"display\": \"inline-block\"}, id=\"detail_map\")\n",
    "                                                 ]\n",
    "\n",
    "                                )]),\n",
    "                                dbc.Row(html.Div([\n",
    "                    #Audio player\n",
    "                    html.Div(style={'width':'40%','marginLeft': 5,'marginTop': 20, 'marginRight': 20,'display':'inline-block',\"border\":\"2px black solid\",'vertical-align': 'top'},                            \n",
    "                           children = [\n",
    "                                     \n",
    "                                     html.Audio(html.Source(src=f'/assets/test_raw_waveform_normalized_upsampled.wav',type='audio/wav'), controls=True, id = 'audio_player_main'), \n",
    "                                     dash_table.DataTable(id = 'event_info_table',style_header={'display':'none'}\n",
    "                                      ,style_cell={\"whiteSpace\": \"pre-line\"}                                      \n",
    "                                      ,data = create_event_infos('HPC.NC_20130403221010_EV')\n",
    "                                      ,style_cell_conditional=[\n",
    "                                        {'if': {'column_id': 'index'},\n",
    "                                        'width': '20%'},\n",
    "                                        {'if': {'column_id': '0'},\n",
    "                                        'width': '80%'},\n",
    "                                    ]\n",
    "                                      ,columns=[{\"name\": i, \"id\": i} for i in ['index','0']])\n",
    "                                      ]),                         \n",
    "                    html.Div(style={'width':'50%', 'marginRight': 10 ,'marginTop': 20, 'display':'inline-block',\"border\":\"2px black solid\"},                             \n",
    "                             children = [\n",
    "                                         html.Div(style={ 'display': 'block','vertical-align':'middle'},id = 'seismogram-div',\n",
    "                                          children = [html.Img(id ='seismogram_img', src = base_seismogram)]),                                        \n",
    "                                         html.Div(style={ 'display': 'block','vertical-align':'middle'},id = 'spectrogram-div',\n",
    "                                          children = [html.Img( id ='spectrogram_img',src = spectrogram_plot)])\n",
    "                                        ])]))\n",
    "                                ])\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    #Output(component_id='tbl', component_property='data'), #Output will be the table (later map)\n",
    "    Output(component_id='depth-slider', component_property= 'value'),\n",
    "    Output(component_id='magnitude-slider', component_property= 'value'),\n",
    "    Output(component_id='date-filter', component_property= 'start_date'),\n",
    "    Output(component_id='date-filter', component_property= 'end_date'),\n",
    "    Output(component_id='earthquake_events_geojson', component_property= 'data'),\n",
    "    Output(component_id='stations_geojson', component_property= 'data'),\n",
    "    Output(component_id='map', component_property= 'style'),\n",
    "    Output(component_id='provider-selector', component_property= 'value'),\n",
    "    Input(component_id='filter-apply-btn', component_property='n_clicks'), #Input button triggers the callback\n",
    "    Input(component_id='filter-reset-btn', component_property='n_clicks'), #Input button triggers the callback\n",
    "    State(component_id='depth-slider', component_property= 'value'),\n",
    "    State(component_id='magnitude-slider', component_property= 'value'),\n",
    "    State(component_id='date-filter', component_property= 'start_date'),\n",
    "    State(component_id='date-filter', component_property= 'end_date'),\n",
    "    State(component_id='provider-selector', component_property= 'value')    \n",
    ")\n",
    "\n",
    "def apply_filter(apply_click,reset_click, depth_value, magnitude_value,start_date,end_date, selected_providers):\n",
    "\n",
    "    #style_to_refresh={'width': '100%', 'height': '50vh', 'margin': \"auto\", \"display\": \"block\"}\n",
    "    style_to_refresh={'width': '70%', 'height': '50vh', 'margin': \"auto\", \"display\": \"inline-block\"}\n",
    "    \n",
    "    # https://towardsdatascience.com/multi-faceted-data-exploration-in-the-browser-using-leaflet-and-amcharts-f74d049d78d9\n",
    "    ctx = dash.callback_context\n",
    "    clicked_element = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    if  clicked_element == 'filter-apply-btn':\n",
    "        \n",
    "        provider_filter = stations_df[(stations_df['provider'].isin(selected_providers)) & (stations_df['station_opened'] >= pd.to_datetime(start_date))]\n",
    "\n",
    "\n",
    "        filtered_stations = list(set(provider_filter['station_id']))\n",
    "        filter_records = df_test['time'].between(pd.to_datetime(start_date),pd.to_datetime(end_date)) & df_test['source_magnitude'].between(magnitude_value[0],magnitude_value[1])\\\n",
    "                         & df_test['source_depth_km'].between(depth_value[0],depth_value[1]) & df_test['station_id'].isin(filtered_stations)\n",
    "        df_filtered = df_test[filter_records]\n",
    "\n",
    "        filtered_datapoints_geojson = dataframe_to_geojson(df_filtered)\n",
    "        filtered_stations_geojson = stations_df_to_geojson(provider_filter)\n",
    "        #filtered_wave_names =  df_filtered.index.tolist()\n",
    "\n",
    "        \n",
    "\n",
    "        #'earthquake_events_geojson'\n",
    "        return [depth_value,magnitude_value,start_date,end_date,filtered_datapoints_geojson,filtered_stations_geojson,style_to_refresh,selected_providers]\n",
    "        #return [df_filtered.head(5).to_dict('records'),depth_value,magnitude_value,start_date,end_date]\n",
    "\n",
    "    elif clicked_element == 'filter-reset-btn':\n",
    "        return [[min_depth,max_depth],[min_magnitude,max_magnitude],min_date,max_date,data_points_geojson,stations_geojson,style_to_refresh,provider_list]\n",
    "       # return [df_test.head(5).to_dict('records'),[min_depth,max_depth],[min_magnitude,max_magnitude],min_date,max_date]\n",
    "\n",
    "    else:\n",
    "        return dash.no_update\n",
    "\n",
    "\n",
    "@app.callback(Output(\"event_info_table\", \"data\"),\n",
    "            Output('seismogram_img', 'src'),\n",
    "            Output('spectrogram_img', 'src'), \n",
    "            Output('audio_player_main', 'src'),\n",
    "            Output('audio_player_main', 'style'),\n",
    "            Input(\"earthquake_events_geojson\", \"click_feature\"),\n",
    "            Input(\"detail_map_earthquake_geojson\", \"click_feature\"),\n",
    "            State('seismogram_img', 'src'),\n",
    "            State('spectrogram_img', 'src'),\n",
    "            State('audio_player_main', 'style')\n",
    ")\n",
    "\n",
    "def select_event(clicked_event,clicked_detail_event, current_seismogram_image, current_spectrogram_image, audi_div_element):\n",
    "\n",
    "    ctx = dash.callback_context\n",
    "    clicked_element = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    #print(ctx.triggered[0])\n",
    "    if clicked_element == \"earthquake_events_geojson\":\n",
    "        if ctx.triggered[0]['value'] is not None:\n",
    "            if ctx.triggered[0]['value']['properties']['cluster'] is True:\n",
    "                return dash.no_update\n",
    "            else:\n",
    "                clicked_event = ctx.triggered[0]['value']\n",
    "    \n",
    "    if clicked_element == \"detail_map_earthquake_geojson\":\n",
    "        clicked_event = ctx.triggered[0]['value']\n",
    "\n",
    "\n",
    "    if clicked_event is not None:\n",
    "    #and clicked_event['properties']['cluster'] is False or clicked_detail_event is not None:\n",
    "    #    if clicked_event is not None:\n",
    "    #        event_selection = clicked_event\n",
    "    #    elif clicked_detail_event is not None:\n",
    "    #        event_selection = clicked_detail_event\n",
    "\n",
    "        #Find the corresponding record from metadata\n",
    "        #print('event selected')\n",
    "        selected_trace_name = clicked_event['properties']['trace_name']\n",
    "        table_data = create_event_infos(selected_trace_name)\n",
    "        selected_event = df_test.loc[selected_trace_name]\n",
    "\n",
    "        \n",
    "        provider_of_waveform = stations_df[(stations_df['network_name'] == selected_event['network_code']) &  (stations_df['station_name'] == selected_event['receiver_code'])]\n",
    "        try:\n",
    "            client = Client(provider_of_waveform['provider'].tolist()[0])\n",
    "\n",
    "            wave = extract_waveform(client, selected_event)\n",
    "\n",
    "            spectrogram_plot = spectrogram_to_uri(wave)\n",
    "            \n",
    "            #wave.filter(\"highpass\", freq=0.5).spectrogram(log = True)\n",
    "\n",
    "            #seismic_plot = fig_to_uri(base_seismogram.plot())\n",
    "            seismic_plot = fig_to_uri(wave)\n",
    "\n",
    "            #print('seismic sound processing..')\n",
    "            #create_seismic_sound_to_dash(wave)\n",
    "            #create_seismic_sound_to_dash_bytes(wave)\n",
    "            #print('FINISHED')\n",
    "            audio_src = html.Source(src=create_seismic_sound_to_dash_bytes(wave),type='audio/wav')\n",
    "            audio_src = create_seismic_sound_to_dash_bytes(wave)\n",
    "            #audio_player_div_player = html.Audio(children = audio_src, controls=True, id ='seismic_audio_player')\n",
    "            audio_player_style = {}\n",
    "\n",
    "            #audio_src = html.Source(src=f'/assets/extracted_seismic_sound.wav',type='audio/wav')\n",
    "            \n",
    "\n",
    "        except:\n",
    "            print('data cannot be found')\n",
    "            return dash.no_update\n",
    "            #src = \n",
    "                                         #html.Div(style={ 'display': 'block','vertical-align':'middle'},id = 'filtered_seismogram-div', children = [html.Img(src = fig_to_uri(filtered_seismogram.plot()))]),\n",
    "        #spectrogram_plot =  spectrogram_to_uri(st[2])\n",
    "        \n",
    "\n",
    "        return [table_data,seismic_plot,spectrogram_plot,audio_src,audio_player_style]\n",
    "\n",
    "    else:\n",
    "        return dash.no_update\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    " # how to draw points      \n",
    "Output(component_id='detail_map_earthquake_geojson', component_property= 'hideout'),\n",
    "Output(component_id='detail_map_earthquake_geojson', component_property= 'data'),\n",
    "Output(component_id='detail_map_stations_geojson', component_property= 'data'),\n",
    "Output(component_id='detail_map', component_property= 'style'),\n",
    "Output(component_id='detail_map_colorbar', component_property= 'min'),\n",
    "Output(component_id='detail_map_colorbar', component_property= 'max'),\n",
    "Output(component_id='detail_map_colorbar', component_property= 'style'),\n",
    "Input(component_id=\"stations_geojson\",component_property=  \"click_feature\"),\n",
    "Input(component_id='filter-apply-btn', component_property='n_clicks'), #Input button triggers the callback\n",
    "Input(component_id='filter-reset-btn', component_property='n_clicks'), #Input button triggers the callback\n",
    "State(component_id='depth-slider', component_property= 'value'),\n",
    "State(component_id='magnitude-slider', component_property= 'value'),\n",
    "State(component_id='date-filter', component_property= 'start_date'),\n",
    "State(component_id='date-filter', component_property= 'end_date'),\n",
    "State(component_id='provider-selector', component_property= 'value') ,\n",
    "State(component_id='stations_geojson', component_property= 'click_feature'),\n",
    " #min=min_magnitude, max=max_magnitude, id = 'detail_map_colorbar'\n",
    ")\n",
    "\n",
    "def show_detail_event(clicked_event, apply_click,reset_click, depth_value, magnitude_value,start_date,end_date, selected_providers,last_selected_station):\n",
    "\n",
    "    style_to_refresh={'width': '30%', 'height': '50vh', 'margin': \"auto\", \"display\": \"inline-block\"}\n",
    "\n",
    "    ctx = dash.callback_context\n",
    "    clicked_element = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "    if  clicked_element == 'filter-apply-btn':\n",
    "        print(last_selected_station)\n",
    "        if last_selected_station is not None and last_selected_station['properties']['cluster'] is False:\n",
    "            \n",
    "            selected_station_id = last_selected_station['properties']['station_id']           \n",
    "        \n",
    "            station_record = stations_df[stations_df['station_id'] == selected_station_id]         \n",
    "            filter_records = df_test['time'].between(pd.to_datetime(start_date),pd.to_datetime(end_date)) & df_test['source_magnitude'].between(magnitude_value[0],magnitude_value[1])\\\n",
    "                         & df_test['source_depth_km'].between(depth_value[0],depth_value[1]) & (df_test['station_id'] == selected_station_id)\n",
    "\n",
    "\n",
    "            df_detail_map_filter  = df_test[filter_records]\n",
    "            try:\n",
    "                filtered_data_points_min_magnitude = min(df_detail_map_filter['source_magnitude'])\n",
    "                filtered_data_points_max_magnitude = max(df_detail_map_filter['source_magnitude'])\n",
    "            except:\n",
    "                filtered_data_points_min_magnitude = min_magnitude\n",
    "                filtered_data_points_max_magnitude = max_magnitude\n",
    "\n",
    "            hideout_update = dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=10),\n",
    "                                                        min=filtered_data_points_min_magnitude, max=filtered_data_points_max_magnitude, colorscale=colorscale)\n",
    "            #print(df_filtered)\n",
    "            #colorbar = dl.Colorbar(colorscale=colorscale, width=20, height=150, min=min_magnitude, max=max_magnitude, unit='km')\n",
    "\n",
    "            filtered_datapoints_geojson = dataframe_to_geojson(df_detail_map_filter)\n",
    "            if len(filtered_datapoints_geojson) == 0:\n",
    "                filtered_datapoints_geojson = None\n",
    "\n",
    "            filtered_stations_geojson = stations_df_to_geojson(station_record)\n",
    "                                    \n",
    "\n",
    "\n",
    "            return [hideout_update,filtered_datapoints_geojson,filtered_stations_geojson,style_to_refresh,filtered_data_points_min_magnitude,filtered_data_points_max_magnitude,dict()]\n",
    "\n",
    "\n",
    "        else:\n",
    "            filtered_data_points_min_magnitude = min_magnitude\n",
    "            filtered_data_points_max_magnitude = max_magnitude\n",
    "            hideout_update = dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=10),\n",
    "                                            min=filtered_data_points_min_magnitude, max=filtered_data_points_max_magnitude, colorscale=colorscale)\n",
    "        \n",
    "            return [hideout_update,None,None,style_to_refresh,filtered_data_points_min_magnitude,filtered_data_points_max_magnitude,dict()]\n",
    "\n",
    "        #filtered_wave_names =  df_filtered.index.tolist()\n",
    "\n",
    "        \n",
    "\n",
    "        #'earthquake_events_geojson'\n",
    "        #return [depth_value,magnitude_value,start_date,end_date,filtered_datapoints_geojson,filtered_stations_geojson,style_to_refresh,selected_providers]\n",
    "        #return [df_filtered.head(5).to_dict('records'),depth_value,magnitude_value,start_date,end_date]\n",
    "\n",
    "    elif clicked_element == 'filter-reset-btn':\n",
    "\n",
    "            filtered_data_points_min_magnitude = min_magnitude\n",
    "            filtered_data_points_max_magnitude = max_magnitude\n",
    "            hideout_update = dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=10),\n",
    "                                            min=filtered_data_points_min_magnitude, max=filtered_data_points_max_magnitude, colorscale=colorscale)\n",
    "        \n",
    "            return [hideout_update,None,None,style_to_refresh,filtered_data_points_min_magnitude,filtered_data_points_max_magnitude,dict()]\n",
    "    \n",
    "    elif clicked_element == 'stations_geojson':        \n",
    "        \n",
    "        if clicked_event is not None and clicked_event['properties']['cluster'] is False:\n",
    "            style_to_refresh={'width': '30%', 'height': '50vh', 'margin': \"auto\", \"display\": \"inline-block\"}\n",
    "            selected_station_id = clicked_event['properties']['station_id']\n",
    "            station_record = stations_df[stations_df['station_id'] == selected_station_id]\n",
    "            #print(selected_station_id)\n",
    "            #print(station_record)\n",
    "            #TODO: trigger hideout\n",
    "            #TODO: add border to distinguish map and detail map\n",
    "\n",
    "            #Refresh color property as well, maybe the scales and differences would be shown in more details\n",
    "            \n",
    "\n",
    "            filter_records = df_test['time'].between(pd.to_datetime(start_date),pd.to_datetime(end_date)) & df_test['source_magnitude'].between(magnitude_value[0],magnitude_value[1])\\\n",
    "                            & df_test['source_depth_km'].between(depth_value[0],depth_value[1]) & (df_test['station_id'] == selected_station_id)\n",
    "            #filter_records = df_test['station_id'] == selected_station_id\n",
    "            df_filtered = df_test[filter_records]\n",
    "            #print(selected_station_id)\n",
    "            try:\n",
    "                filtered_data_points_min_magnitude = min(df_filtered['source_magnitude'])\n",
    "                filtered_data_points_max_magnitude = max(df_filtered['source_magnitude'])\n",
    "            except:\n",
    "                filtered_data_points_min_magnitude = min_magnitude\n",
    "                filtered_data_points_max_magnitude = max_magnitude\n",
    "\n",
    "            hideout_update = dict(colorProp=color_prop, circleOptions=dict(fillOpacity=1, stroke=False, radius=10),\n",
    "                                                        min=filtered_data_points_min_magnitude, max=filtered_data_points_max_magnitude, colorscale=colorscale)\n",
    "            #print(df_filtered)\n",
    "            #colorbar = dl.Colorbar(colorscale=colorscale, width=20, height=150, min=min_magnitude, max=max_magnitude, unit='km')\n",
    "\n",
    "            filtered_datapoints_geojson = dataframe_to_geojson(df_filtered)\n",
    "            if len(filtered_datapoints_geojson) == 0:\n",
    "                filtered_datapoints_geojson = None\n",
    "            filtered_stations_geojson = stations_df_to_geojson(station_record)        \n",
    "\n",
    "            return [hideout_update,filtered_datapoints_geojson,filtered_stations_geojson,style_to_refresh,filtered_data_points_min_magnitude,filtered_data_points_max_magnitude,dict()]\n",
    "\n",
    "        else:\n",
    "            return dash.no_update\n",
    "\n",
    "\n",
    "'''\n",
    "app.layout = html.Div([\n",
    "    dl.Map(children=[\n",
    "        dl.TileLayer(),\n",
    "        dl.GeoJSON(data=geojson, options=dict(filter=geojson_filter), hideout=dd_defaults, id=\"geojson\", zoomToBounds=True)\n",
    "    ], style={'width': '100%', 'height': '50vh', 'margin': \"auto\", \"display\": \"block\"}, id=\"map\"),\n",
    "    dcc.Dropdown(id=\"dd\", value=dd_defaults, options=dd_options, clearable=False, multi=True)\n",
    "])\n",
    "'''\n",
    "# Link drop down to geojson hideout prop (could be done with a normal callback, but clientside is more performant).\n",
    "#app.clientside_callback(\"function(x){return x;}\", Outp\n",
    "# ut(\"geojson\", \"hideout\"), Input(\"dd\", \"value\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #app.run_server()\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
